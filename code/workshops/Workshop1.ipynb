{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256e27b6-b663-406d-a42e-3f8fd704d7fe",
   "metadata": {},
   "source": [
    "# Workshop 1: Analyzing connectomics datasets: V1dd\n",
    "\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "<font size=4> The function of the nervous system arises out of a combination of the properties of individual neurons and the properties of how they are connected into a larger network. The central goal of <b>connectomics</b> is to produce complete maps of the connectivity of the nervous system with synaptic resolution and analyze them to better understand the organization, development, and function of the nervous system. </font>\n",
    "\n",
    "<font size=4><b>Electron Microscopy (EM) data enables morphological reconstruction of neurons and resolution of their synaptic connectivity </b>. The V1DD dataset is one of the largest volume EM datasets currently available, and spans all layers of mouse visual cortex. We will be using this dataset to query the connectivity between neurons in the visual cortex. </font>\n",
    "\n",
    "<b> The V1DD dataset is newly public. </b> Previous years of this course have used the [MICrONS Dataset](https://www.microns-explorer.org/), which is also a cubic millimeter volume of mouse visual cortex. Both datasets are available for the use of this course, but we will cover V1DD in Week 1.\n",
    "\n",
    "<h3> Workshop aims</h3>\n",
    "<ul>\n",
    "    <li> Understand what are the major classes of cell types in cortex</li>\n",
    "    <li> Understand the basics of how synaptic connectivity is measured in EM connectomics</li>\n",
    "    <li> Look at the relationship between the structure of networks and cell type connectivity</li>\n",
    "    <li> Look at the relationship between functional tuning properties of neurons and how they are connected in the network </li>\n",
    "</ul>\n",
    "    \n",
    "\n",
    "<h4> Workshop 1 will cover: </h4>\n",
    "<ol> \n",
    "    <li>Reconstructions of individual neurons</li>\n",
    "    <li>Connectivity of individual neurons</li>\n",
    "    <li>Connectivity between cell types</li>\n",
    "    <li>Connectivity by target type (spine, soma, shaft)</li>\n",
    "</ol>\n",
    "\n",
    "<h4> Workshop 2 will cover: </h4>\n",
    "<ol> \n",
    "    <li>Connection probability as a function of distance</li>\n",
    "    <li>The relationship between structure and function </li>\n",
    "    <li>Designing null models to test for meaningful connectivity </li>\n",
    "</ol>\n",
    "\n",
    "<em> Note on data access: </em> To make this workshop easier, we already queried the most of the data needed for this exercise from the database. We have made it available as versioned files that can be read with pandas. The entire dataset is hosted using the <a href=https://caveconnectome.github.io/sections/cave_overview.html> Connectome Annotation Versioning Engine (CAVE) </a>. A separate notebook shows how to use CAVE to generate the files used in this notebook: `code/solutions/DataProducts.ipynb`\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1656c48-1dfa-4d57-a90e-045a8760a606",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "This cell sets up a variable called `data_root` that generalizes the data directory across systems, whether you are using CodeOcean or the prepared data drives\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cf2d8-5c82-4f0c-a61b-723dd93cbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import join as pjoin\n",
    "import platform\n",
    "\n",
    "# Add the directory for the data and utilities\n",
    "mat_version = 1196\n",
    "\n",
    "platstring = platform.platform()\n",
    "system = platform.system()\n",
    "if system == \"Darwin\":\n",
    "    # macOS\n",
    "    data_root = \"/Volumes/Brain2025/\"\n",
    "elif system == \"Windows\":\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif \"amzn\" in platstring:\n",
    "    # then on CodeOcean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2025/\"\n",
    "\n",
    "# Set the directory to load prepared data and utility code\n",
    "data_dir = pjoin(data_root, f\"v1dd_{mat_version}\")\n",
    "utils_dir = pjoin(\"utils\")\n",
    "\n",
    "# Add utilities to path\n",
    "sys.path.append(utils_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61655a09-c7f4-47c0-8df8-7ce07b006fc8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2> Import packages </h2>\n",
    "   \n",
    "<b> The CAVEclient</b> is a python library that facilitates communication with a CAVE system. For convenience, we also use the package <b>skeleton_plot</b> which handles rendering the precomputed skeletons. \n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43aa613-3805-43fd-b169-9a42eadc28ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from caveclient import CAVEclient\n",
    "import skeleton_plot as skelplot\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_array\n",
    "from typing import Union, Optional\n",
    "from utils import check_index, adjacencyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79a79e-df08-4e85-b89e-c6c48b006ddb",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "   \n",
    "<b> CAVE account setup</b>\n",
    "\n",
    "<p>In order to manage server traffic, every user needs to create a CAVE account and download a user token to access CAVE's services programmatically. The CAVE infrastructure can be read about in <a href='https://doi.org/10.1038/s41592-024-02426-z'>more detail in the MICrONS Nature Package</a>. \n",
    "\n",
    "<b> A Google account (or Google-enabled account) is required to create a CAVE account.</b>\n",
    "\n",
    "Run the cell below and follow the set up instructions; enter the token first, then enter 'y' when prompted\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a55467-3393-4e56-837a-953578393566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Generation and Setup\n",
    "CAVEclient.setup_token(\"https://global.em.brain.allentech.org\")\n",
    "\n",
    "# Initialize CAVEclient\n",
    "client = CAVEclient(datastack_name=\"v1dd_public\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f3f90-fa2f-4c0c-8295-e103e154d89a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p><b>Tip for CodeOcean users</b>: you can add the the CAVEclient token to your capsule's secrets, so you do not have to enter it every time you run the notebook. If you chose to use EM data for your project in Week 2 we can show you how. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5cfa7-7171-44d2-9197-3715176b6a00",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "## Interactive session in neuroglancer\n",
    "\n",
    "Instructions in the <a href=https://allenswdb.github.io/anatomy/microns-em/em-neuroglancer.html> DataBook: Neuroglancer </a>\n",
    "\n",
    "<font size=4> <a href=https://spelunker.cave-explorer.org/#!middleauth+https://global.daf-apis.com/nglstate/api/v1/4876435155058688> V1DD Neuroglancer Explorer </a> </font>\n",
    "\n",
    "You will be prompted for a google login. Use the same account you used to authenticate your CAVE token\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaae40e-7027-47d4-85b3-ef0fb415794d",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "## Proofreading and data quality\n",
    "\n",
    "Understanding this variablity in data quality is critical when interpretting electron microscopy reconstructions.\n",
    "\n",
    "Automated segmentation of neuronal processes in dense EM imaging is challenging at the size of entire neurons, which can have millimeters of axons and dendrites. The automated segmentation algorithms used in the EM data for this project are not perfect, and so proofreading is necessary to obtain accurate reconstructions of a cell and confidence in the connectivity\n",
    "\n",
    "In general, the **dendrites** of single-soma detected neurons are considered trustworthy, even without proofreading. However the **axons** require manual effort to both clean and extend. \n",
    "\n",
    "For details on the proofreading status see: \n",
    "\n",
    "*  `code/solutions/DataProducts.ipynb` for how the data we use today was generated\n",
    "* Proofreading page in the <a href=https://allenswdb.github.io/anatomy/microns-em/proofreading.html> SWDB databook</a>\n",
    "\n",
    "<b> For this workshop, we treat all cells with at least `axon_partially_extended` as equally trustworth.</b> This may not be a safe assumption for all analysis, and we are happy to provide more guidance depending on the research question.\n",
    "\n",
    "<font size=3>Load the prepared variables: <code>dendrite_proof_root_ids</code> and <code>axon_proof_root_ids</code> </font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2010d44-b8ee-4c02-8e25-ddb20745cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads cells with axon and dendrite proofreading\n",
    "dendrite_proof_root_ids = np.load(\n",
    "    pjoin(data_dir, f\"proofread_dendrite_list_{mat_version}.npy\")\n",
    ")\n",
    "axon_proof_root_ids = np.load(pjoin(data_dir, f\"proofread_axon_list_{mat_version}.npy\"))\n",
    "\n",
    "print(\n",
    "    f\"There are {len(dendrite_proof_root_ids)} cells with acceptable dendrites, and {len(axon_proof_root_ids)} cells with axon proofreading\"\n",
    ")\n",
    "print(\n",
    "    f\"The number of cells with usable axons and dendrites is: {(np.isin(axon_proof_root_ids, dendrite_proof_root_ids).sum())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915aa41-6325-4734-9555-9e6131d455fa",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "## Neuron morphology: representing neurons as skeletons\n",
    "\n",
    "Often in thinking about neurons, you want to measure things along a linear dimension of a neuron.\n",
    "\n",
    "However, the segmentation and meshes are a complex 3D shape that makes this non-trivial. There are methods for reducing the shape of a segmented neuron down to a linear tree like structure usually referred to as a **skeleton**. We have precalculated skeletons for a large number of cells in the dataset, and make the skeleton generation available on our server, on demand.\n",
    "\n",
    "*Note*: The meshes you see in Neuroglancer are available to download through the python client `cloud-volume`, and can be loaded for analysis and visualization in other tools. This is useful for some types of analysis (and for making beautiful renders of neurons), but we will not cover that in this course.\n",
    "\n",
    "<font size=4> First, define a convenience function for plotting skeletons. </font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079dcbc-7c1f-4208-afee-b059e1dac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color map for the different comparments. You may adjust these to your asthetic.\n",
    "skel_color_map = {3: \"firebrick\", 4: \"salmon\", 2: \"steelblue\", 1: \"olive\"}\n",
    "\n",
    "\n",
    "def plot_skeleton(sk_d: dict, plot_soma=True, ax=None):\n",
    "    \"\"\"Plots a skeleton.\n",
    "\n",
    "    Args:\n",
    "        sk: skeleton dict as returned from CAVEclient\n",
    "\n",
    "    Returns:\n",
    "        ax: plot axes\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(7, 10), dpi=150)\n",
    "\n",
    "    skelplot.plot_tools.plot_verts(\n",
    "        np.array(sk_d[\"vertices\"]),\n",
    "        np.array(sk_d[\"edges\"]),\n",
    "        radius=np.array(sk_d[\"radius\"]) / 1000 * 1,\n",
    "        ax=ax,\n",
    "        skel_colors=sk_d[\"compartment\"],\n",
    "        title=\"\",\n",
    "        skel_alpha=1.0,\n",
    "        line_width=5,\n",
    "        x=\"x\",  # You can alter the projection direction by changing this to `y` or `z`\n",
    "        y=\"y\",  # You can alter the projection direction by changing this to `x` or `z`\n",
    "        plot_soma=plot_soma,\n",
    "        soma_node=sk_d[\"root\"],\n",
    "        color=\"darkslategray\",\n",
    "        soma_size=120,\n",
    "        invert_y=True,\n",
    "        skel_color_map=skel_color_map,\n",
    "        x_min_max=None,\n",
    "        y_min_max=None,\n",
    "        capstyle=\"round\",\n",
    "        joinstyle=\"round\",\n",
    "    )\n",
    "\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9201db2-11ca-4aca-bea1-42a66edaa0ae",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<font size=4> Select one of the axon-proofread cells to plot as a skeleton. </font>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec530b7-5530-4092-85b5-0d28f6ca3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select from the cells which are fully extended\n",
    "root_id = axon_proof_root_ids[1]  # iterate this number to choose a different cell\n",
    "\n",
    "# Query the skeleton from CAVEclient\n",
    "sk_d = client.skeleton.get_skeleton(root_id, output_format=\"dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4ecfe-1c1c-4f2d-8c49-862825141333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot skeleton in 2D\n",
    "ax = plot_skeleton(sk_d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4998b81-528e-4f31-8b42-252db9aec140",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h4> Morphological compartment names </h4>\n",
    "\n",
    "<p> The compartment types defined at each vertex adhere to standardized conventions for neuronal morphologies saved as swc files (for more information, see here: www.neuromorpho.org). </p>\n",
    "    \n",
    "These conventions are as follows:\n",
    "<ul> \n",
    "    <li> 0 - undefined </li>\n",
    "    <li> 1 - soma (default color 'olive') </li>\n",
    "    <li> 2 - axon (default color 'steelblue') </li>\n",
    "    <li> 3 - (basal) dendrite (default color 'firebrick' red) </li>\n",
    "    <li> 4 - apical dendrite </li>\n",
    "    <li> 5+ - custom </li>\n",
    "</ul>\n",
    "\n",
    "In most of these neurons, distinctions were not made between basal or apical dendrites - therefore dendrites should almost exclusively map to compartment type \"3\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c9993-c0a4-4485-8a7e-a4c7c70b9354",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1:</b> Plot several different skeletons by changing the <code> root_id </code> entry. You can either iterate through the <code>axon_proof_root_ids</code> list, or paste the segment id from neuroglancer.\n",
    "\n",
    "<b>Discussion:</b> What information do you lose going from 3D neuron meshes (neuroglancer) to 2D skeleton projections? What becomes more clear?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15496047-cdb2-493a-841e-264bd24cb3f2",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "## Synapse information\n",
    "\n",
    "While synapses are stored as any other CAVE table in the database, in this case `synapses_v1dd`, this table is much larger than any other table at almost <b>640 million rows</b>, and it works best when queried in a directed way.\n",
    "\n",
    "For today's workshop we have collected all of the input and output synapses for the proofread cells When accessing CAVE, the `synapse_query()` function allows you to query the synapse table in a more convenient way than most other tables. In particular, the `pre_ids` and `post_ids` let you specify which root id (or collection of root ids) you want to query, with pre_ids indicating the collection of presynaptic neurons and post_ids the collection of postsynaptic neurons.\n",
    "\n",
    "Note that synapse queries always return the list of every synapse between the neurons in the query, even if there are multiple synapses between the same pair of neurons.\n",
    "\n",
    "A common pattern to generate a list of connections between unique pairs of neurons is to group by the root ids of the presynaptic and postsynaptic neurons and then count the number of synapses between them. \n",
    "\n",
    "<font size=4> Load the table of connections between proofread cells (about <b> 8 million </b> entries) </font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fec735-8be4-4e91-a266-2d726a9a9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_df = pd.read_feather(\n",
    "    f\"{data_dir}/syn_df_all_to_proofread_to_all_{mat_version}.feather\"\n",
    ")\n",
    "\n",
    "print(syn_df.shape)\n",
    "\n",
    "syn_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0895ff7-c9d0-476b-a8b7-9531065d04c6",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "\n",
    "<ul>This table has a number of columns, we will highlight the most important\n",
    "    <li><b> id:</b> a unique ID for each synapse </li>\n",
    "    <li><b> pre_pt_root_id:</b> the segmentation ID of the pre-synaptic compartment</li>\n",
    "    <li><b> post_pt_root_id:</b> the segmentation ID of the post-synaptic compartment</li>\n",
    "    <li><b> size:</b> a measure of the synapse size (the number of 4,4,40 nm voxels in the synapse mask) best available metric of synaptic weight</li>\n",
    "    <li><b> ctr_pt_position_{x,y,z}:</b> the location of the synapse in the cleft, stored here in nanometers</li>\n",
    "    <li><b> pre_pt_position_{x,y,z}:</b> a point just in the presynaptic compartment of synapse (used to lookup pre_root_id), stored here in nanometers</li>\n",
    "    <li><b> post_pt_position_{x,y,z}:</b> a point just in the postsynaptic compartment of synapse (used to lookup post_pt_root_id), stored here in nanomaters</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642616ce-ab42-4477-a38e-8dd3913c4933",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "## Combining neuron morphology & synapses\n",
    "\n",
    "<p> Next we will visualize the synapses on the skeleton of your cell of interest. </p>\n",
    "\n",
    "<p> Here we define a convenience function for robustly filtering the synapse table by pre- or post-synaptic partners. You will use this through the rest of the exercises. </p> \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83c9bc-ee96-4227-ad05-577542ffd2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_synapse_table(\n",
    "    synapse_table: pd.DataFrame, pre_root_ids=None, post_root_ids=None\n",
    "):\n",
    "    \"\"\"Filter synapse table by pre and post root ids.\n",
    "\n",
    "    Args:\n",
    "        synapse_table: synapse table with pre_pt_root_ids and post_pt_root_ids as pd.DataFrame\n",
    "        pre_root_ids: np.ndarray, list or pd.Series if root_ids to filter on the presynaptic side\n",
    "        post_root_ids: np.ndarray, list or pd.Series if root_ids to filter on the postsynaptic side\n",
    "\n",
    "    Returns:\n",
    "        synapse_table: filtered synapse table\n",
    "    \"\"\"\n",
    "\n",
    "    if pre_root_ids is not None:\n",
    "        assert isinstance(pre_root_ids, (np.ndarray, list, pd.core.series.Series)), (\n",
    "            f\"IDs have to be of type np.ndarray, list or pd.Series; got {type(pre_root_ids)}\"\n",
    "        )\n",
    "        pre_mask = np.isin(synapse_table[\"pre_pt_root_id\"], pre_root_ids)\n",
    "    else:\n",
    "        pre_mask = np.ones(len(synapse_table), dtype=bool)\n",
    "\n",
    "    if post_root_ids is not None:\n",
    "        assert isinstance(post_root_ids, (np.ndarray, list, pd.core.series.Series)), (\n",
    "            f\"IDs have to be of type np.ndarray, list or pd.Series; got {type(pre_root_ids)}\"\n",
    "        )\n",
    "        post_mask = np.isin(synapse_table[\"post_pt_root_id\"], post_root_ids)\n",
    "    else:\n",
    "        post_mask = np.ones(len(synapse_table), dtype=bool)\n",
    "\n",
    "    return synapse_table[pre_mask & post_mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2bc65-84a3-4323-89ce-e746fb36a0c9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "<h3> Collect the output synapses for your cell of interest. </h3>\n",
    "\n",
    "The nomenclature here is that you want synapses where your cell is the **presynaptic** partner\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c085223-dbe9-426e-b1b9-4638b7bbc38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select from the cells which are fully extended\n",
    "root_id = axon_proof_root_ids[1]  # iterate this number to choose a different cell\n",
    "\n",
    "# Query the skeleton from CAVEclient\n",
    "sk_d = client.skeleton.get_skeleton(root_id, output_format=\"dict\")\n",
    "\n",
    "pre_syns = filter_synapse_table(syn_df, pre_root_ids=[root_id])\n",
    "\n",
    "pre_syns.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74cdc1-7648-46d0-9997-01b76f483427",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "    \n",
    "Add the synapse positions to yours skeleton. We use:\n",
    "\n",
    "<ul>\n",
    "    <li><b> ctr_pt_position_{x,y,z}:</b> the location of the synapse in the cleft, stored here in nanometers</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a957d9-fc03-4b12-9cbe-e335028d9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your skeleton and overlay synapses\n",
    "ax = plot_skeleton(sk_d)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=pre_syns,\n",
    "    x=\"ctr_pt_position_x\",\n",
    "    y=\"ctr_pt_position_y\",\n",
    "    s=5,\n",
    "    color=\"b\",\n",
    "    ax=ax,\n",
    "    edgecolor=None,\n",
    "    zorder=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd9281-5a51-41d6-8c1e-29871f9573e8",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 2:</b> Now use the filter function above to create a dataframe of all postsynaptic synapses and create a version of the plot above that includes these input synapses. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331c399-897c-4f21-aef0-1b8ee589e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the synapses where your root_id is postsynaptic ('downstream'); the inputs to your cell\n",
    "\n",
    "\n",
    "# Plot skeleton with input and output synapses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5a0a1-1d14-4d90-8c4f-8a1252c94fb1",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 3:</b> Repeat the plotting code up to this point with a different neuron, changing the <code> root_id </code> variable above. \n",
    "\n",
    "<p> Try several, until you see something you haven't seen before. </p>\n",
    "\n",
    "<b> Discussion </b>: what do you notice about the distribution of synapses relative to the soma of different cells? Above/below? Narrow or broad? What about the density of synapses on parts of the dendrites or axons?\n",
    "\n",
    "How would you quantify these features?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e167df3-82cb-4806-b7a9-3250220dd13e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Synapse matrix\n",
    "\n",
    "The synapses between neurons create a network of synaptic connections. One way of visualizing this connectivity is in matrix form. \n",
    "\n",
    "For now, we will limit ourselves to the synapses between the proofread neurons.\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3ad0f-e8ad-4683-9d0e-5b50437d0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids of all proofread cells with both axon and dendrite proofreading\n",
    "proof_root_ids = axon_proof_root_ids[\n",
    "    np.isin(axon_proof_root_ids, dendrite_proof_root_ids)\n",
    "]\n",
    "\n",
    "# filter for synapses between the proofread cells (pre and post)\n",
    "proof_proof_syn_table = filter_synapse_table(\n",
    "    syn_df, pre_root_ids=proof_root_ids, post_root_ids=proof_root_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007c105-6103-42ec-b35f-40c8a2fa2c7e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Next we will make an **adjacency plot** from the tabular synapse data, turning it into a matrix the describes the connection strength between all possible partners. For convenience we have provided a function `make_adjacency` to perform the ordered groupbys and aggregations. \n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96734b8d-b62d-47d1-a9fc-6fe1c2b17eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import check_index\n",
    "\n",
    "\n",
    "def make_adjacency(\n",
    "    synapses,\n",
    "    source_cell_index: Union[pd.Index, pd.DataFrame, pd.Series, np.ndarray, list],\n",
    "    target_cell_index: Optional[\n",
    "        Union[pd.Index, pd.DataFrame, pd.Series, np.ndarray, list]\n",
    "    ] = None,\n",
    "    aggfunc=\"binary\",\n",
    "    return_as=\"dense\",\n",
    ") -> Union[csr_array, np.ndarray]:\n",
    "    source_cell_index = check_index(source_cell_index)\n",
    "    if target_cell_index is None:\n",
    "        target_cell_index = source_cell_index\n",
    "    else:\n",
    "        target_cell_index = check_index(target_cell_index)\n",
    "    synapses = synapses.query(\n",
    "        \"pre_pt_root_id in @source_cell_index and post_pt_root_id in @target_cell_index\"\n",
    "    )\n",
    "    groupby = synapses.groupby([\"pre_pt_root_id\", \"post_pt_root_id\"])\n",
    "    if aggfunc == \"count\":\n",
    "        edges = groupby.size().rename(\"weight\").reset_index()\n",
    "    elif aggfunc == \"binary\":\n",
    "        edges = groupby.size().transform(lambda x: x > 0).rename(\"weight\").reset_index()\n",
    "    else:\n",
    "        edges = groupby[\"size\"].agg(aggfunc).rename(\"weight\").reset_index()\n",
    "    # make sure that the adjacency matrix is sorted the same as the input cell index\n",
    "    edges[\"source_index\"] = source_cell_index.get_indexer(edges[\"pre_pt_root_id\"])\n",
    "    edges[\"target_index\"] = target_cell_index.get_indexer(edges[\"post_pt_root_id\"])\n",
    "    adjacency = csr_array(\n",
    "        (edges[\"weight\"], (edges[\"source_index\"], edges[\"target_index\"])),\n",
    "        shape=(len(source_cell_index), len(target_cell_index)),\n",
    "        dtype=edges[\"weight\"].dtype,\n",
    "    )\n",
    "    # NOTE: for many applications working with sparse matrices is more efficient\n",
    "    # but for ease of use and visualization in this workshop we return a dense matrix\n",
    "    if return_as == \"dense\":\n",
    "        adjacency = adjacency.todense()\n",
    "    elif return_as == \"sparse\":\n",
    "        pass  # already in sparse format\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown return_as type: {return_as}\")\n",
    "    return adjacency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a475238-ae53-4de9-b181-d0d02ec9e564",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Each synapse has a `size` value assigned to it. How to aggregate the sizes from multiple synapes between two neurons depends on the research question. Synapse sizes vary by a lot and are related to the physiological strength of a synapse ([Holler et al., 2021](https://www.nature.com/articles/s41586-020-03134-2)). \n",
    "\n",
    "<font size=4> First, we will ignore the synapse size and strength and only look at <b>binary (connected yes/no) connectivity</b>. There are other measures of connectivity you can explore below that changes how the network appears. </font3>\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60156fe5-56f1-4fb1-87ca-7b1024562db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_mat = make_adjacency(proof_proof_syn_table, proof_root_ids, aggfunc=\"binary\")\n",
    "syn_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b62d4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "It looks like many of the values in the adjacency matrix array are `False`. In other words, most of the neurons in the proofread dataset are not connected to each other. How can we look at the places where there are connections? We can use the `np.nonzero()` function to get the indices of the non-zero (`True`) values in the array.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703284f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 10 nonzero values in the array\n",
    "row_indices, column_indices = np.nonzero(syn_mat)\n",
    "print(\"Row indices:\", row_indices[:10])\n",
    "print(\"Column indices:\", column_indices[:10])\n",
    "print(\"Matrix values:\", syn_mat[row_indices[:10], column_indices[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06509984",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "<b> Discussion </b>: what does it mean that all of the first 10 values we looked at share the same row index?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b26721",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Now, let's move on to plotting the entire matrix.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", font_scale=1.0)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=200)\n",
    "\n",
    "sns.heatmap(\n",
    "    syn_mat,\n",
    "    cbar=False,\n",
    "    cmap=\"Greys\",\n",
    "    xticklabels=False,\n",
    "    yticklabels=False,\n",
    "    square=True,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(True)\n",
    "_ = ax.set(\n",
    "    xlabel=\"Postsynaptic cell\",\n",
    "    ylabel=\"Presynaptic cell\",\n",
    "    title=\"Adjacency matrix between proofread cells\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5c080f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_edges = len(row_indices)\n",
    "n_possible_edges = syn_mat.shape[0] * syn_mat.shape[1]\n",
    "print(f\"Number of edges: {n_edges}\")\n",
    "print(f\"Number of possible edges: {n_possible_edges}\")\n",
    "print(f\"Fraction of possible edges: {n_edges / n_possible_edges:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae8520-833a-4096-9a65-10d974330e30",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 3:</b> The matrix above only contains connections between <b>axon-proofread neurons</b>. Because many more dendrites of cells in the V1DD dataset are well-reconstructed <b>we can consider more connections than just the ones between proofread neurons.</b> Therefore, the connectivity matrix of analyzable connections forms a rectangular matrix. \n",
    "    \n",
    "What is the size of the matrix between the proofread neurons and all neurons with a cell body in the dataset?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607d535-819e-4e02-9c08-5985393f7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select synapses from proofread cells onto all cells\n",
    "\n",
    "# make adjanceny matrix from proofread cells onto all cells\n",
    "\n",
    "# print shape of the matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb45d378-a7cb-4d96-ac25-ca13b1e6e81a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h4> Consider: different measures of synaptic strength </h4>\n",
    "\n",
    "When creating a connectivity matrix, how you measure synaptic strength can make a difference in your analysis. For EM data there are 3 common ways of reporting connection strength:\n",
    "\n",
    "<ol>\n",
    "    <li> <b> Binary connectivity:</b> whether two cells are connected at all, as shown above.</li>\n",
    "    <li> <b> Synaptic count:</b> the total number of synapses that are part of the connection. This is typical of the Fly connectome where <code>count</code> captures much of the connection diversity. The modal <code>count</code> in mouse cortex is much lower.</li>\n",
    "    <li> <b> Synaptic size:</b> the size of the postsynaptic density at every connection, generally aggregated as <code>sum</code> or <code>mean</code> for each unique connection.</li>\n",
    "    \n",
    "</ol>\n",
    "How to take synapse size and number into account depends on the specific analysis. \n",
    "\n",
    "The `size` reported in the V1DD dataset measures the synaptic cleft as segmented by the automated classifier in voxels (3d pixels, a measure of volume). These are correlated to anatomical measures such as synaptic area and spine head volumes (for excitatory synapses). \n",
    "\n",
    "Let's replot the <b>square matrix</b> with the <code>sum</code> of synapses sizes between each connected pair.\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1a84b-b675-42b8-ae3c-4242138331dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ids of all proofread cells (same as for the binary connectivity)\n",
    "proof_root_ids = axon_proof_root_ids[\n",
    "    np.isin(axon_proof_root_ids, dendrite_proof_root_ids)\n",
    "]\n",
    "\n",
    "# Now with the aggregation function set to 'mean' synapse size\n",
    "syn_mat = make_adjacency(syn_df, source_cell_index=proof_root_ids, aggfunc=\"sum\")\n",
    "\n",
    "# show the first 10 nonzero values in the array\n",
    "row_indices, column_indices = np.nonzero(syn_mat)\n",
    "print(\"Row indices:\", row_indices[:10])\n",
    "print(\"Column indices:\", column_indices[:10])\n",
    "print(\"Matrix values:\", syn_mat[row_indices[:10], column_indices[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644f75d-ab6c-447d-a473-5d1acdd3e726",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "The matrix values are now **sum of size** rather than the True/False. It is useful to understand the full range of synaptic strength represented, plotted below first on a linear axis then a log axis\n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d6502",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), dpi=150)\n",
    "\n",
    "# collect the synaptic weights that are non-zero\n",
    "edge_weights = syn_mat[row_indices, column_indices]\n",
    "\n",
    "# Histogram on linear-x\n",
    "ax = axs[0]\n",
    "sns.histplot(\n",
    "    edge_weights,\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "ax.set(xlabel=\"Sum synapse size (voxels)\", ylabel=\"Number of connections\")\n",
    "\n",
    "# Histogram on log-x\n",
    "ax = axs[1]\n",
    "sns.histplot(\n",
    "    edge_weights,\n",
    "    kde=True,\n",
    "    bins=100,\n",
    "    ax=ax,\n",
    "    log_scale=True\n",
    ")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "ax.set(xlabel=\"Sum synapse size (voxels - log scale)\", ylabel=\"Number of connections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c8fe80-a63d-4a07-b52b-344e38d8e7d8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Replot the square matrix with `sum` of synapse size. \n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef246554",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=200)\n",
    "sns.heatmap(\n",
    "    syn_mat,\n",
    "    cbar=True,\n",
    "    cmap=\"Greys\",\n",
    "    xticklabels=False,\n",
    "    yticklabels=False,\n",
    "    square=True,\n",
    "    vmax=3000,  # set the upper bound on color scale so that we can see more edges\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": \"Mean synapse size (nm)\", \"shrink\": 0.5},\n",
    ")\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(True)\n",
    "_ = ax.set(\n",
    "    xlabel=\"Postsynaptic cell\",\n",
    "    ylabel=\"Presynaptic cell\",\n",
    "    title=\"Adjacency matrix between proofread cells\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575d5a7-433b-4e80-9e25-8c013cffcca2",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Depending on the connection type, number of synapses might be the more important measure (see [Dorkenwald et al., 2022](https://elifesciences.org/articles/76120) for deeper dive into synapse size and counts). \n",
    "\n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39772c44-fc6a-4ad0-826a-a19610be751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate adjacenty matrix with a count of synapses\n",
    "syn_mat = make_adjacency(syn_df, proof_root_ids, aggfunc=lambda x: np.sum(x > 0))\n",
    "\n",
    "# Histogram on linear-x\n",
    "fig, ax = plt.subplots(figsize=(5, 4), dpi=150)\n",
    "edge_weights = syn_mat[row_indices, column_indices]\n",
    "sns.histplot(\n",
    "    edge_weights,\n",
    "    discrete=True,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "ax.set(xlabel=\"Number of synapses per connection\", ylabel=\"Number of connections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9178b5a9",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Next we plot the <b>number of synapses per connection</b> or the <code>count</code>(we limit the colorbar to a maximum of 5 but the actual max number is much higher):\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51186010",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=200)\n",
    "sns.heatmap(\n",
    "    syn_mat,\n",
    "    cbar=True,\n",
    "    cmap=\"Greys\",\n",
    "    xticklabels=False,\n",
    "    yticklabels=False,\n",
    "    square=True,\n",
    "    vmax=5,  # clip the color scale to 5 to see more edges\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": \"Number of synapses\", \"shrink\": 0.5},\n",
    ")\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(True)\n",
    "_ = ax.set(\n",
    "    xlabel=\"Postsynaptic cell\",\n",
    "    ylabel=\"Presynaptic cell\",\n",
    "    title=\"Adjacency matrix between proofread cells\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d707724-8a7e-4d11-8d46-c8315b24da3f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Cell type tables\n",
    "\n",
    "Identifying the putative ‘cell type’ from the EM morphology is a process that involves both manual and automatic classifications. Subsets of the dataset have been manually classified by anatomists at the Allen Institute, and these ground truth labels used to train and refine different automated ‘feature classifiers’ over time. \n",
    "\n",
    "Two of the most predictive features for broad cell type are:\n",
    "\n",
    "<ul>\n",
    "    <li>Soma location (in units of depth from pial surface). This captures <b>cortical layer diversity</b></li>\n",
    "    <li>Soma size (in units of volume). This is a strong proxy of many types of <b>cell morpholigical diversity</b></li>\n",
    "</ul>\n",
    "\n",
    "<font size=4>Load the cell types data and plot all the cells by these two features</font>\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d02398-bb67-4142-976a-7c090f9bad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df = pd.read_feather(f\"{data_dir}/soma_and_cell_type_{mat_version}.feather\")\n",
    "\n",
    "cell_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b542723c-fb2e-4fed-8d84-0ddf9fe9cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column that is soma depth in consistent units\n",
    "cell_df['depth_um'] = cell_df['pt_position_trform_y'] / 1_000 # from nm to um\n",
    "\n",
    "# Plot cell volume by depth\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=150)\n",
    "ax.tick_params(labelsize=14)\n",
    "sns.scatterplot(\n",
    "    data=cell_df,\n",
    "    x=\"volume\",\n",
    "    y=\"depth_um\",\n",
    "    size=1,\n",
    "    edgecolor=None,\n",
    "    alpha=0.005,\n",
    "    color=\"k\",\n",
    "    ax=ax,\n",
    "    legend=False,\n",
    ")\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(r\"Volume ($\\mu m^3$)\", fontsize=16)\n",
    "ax.set_ylabel(r\"Depth ($\\mu m$)\", fontsize=16)\n",
    "ax.set_xlim(0, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfc5ca-4063-4657-9dd5-c6efd70452d0",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Using the automated cell types\n",
    "\n",
    "Many of these automated cell type definitions were established and refined for the [MICrONS Dataset](https://www.microns-explorer.org/) including: \n",
    "\n",
    "<ul>\n",
    "    <li> Perisomatic cell features <a href=https://www.nature.com/articles/s41586-024-07765-7>(Elabbady et al.)</a> </li>\n",
    "    <li> Morphology and connectivity features <a href=https://www.nature.com/articles/s41586-024-07780-8>(Schneider-Mizell et al.)</a> </li>\n",
    "</ul>\n",
    "\n",
    "The process of applying these labels to the V1DD dataset is ongoing, but we will use cell typing from the <code>cell_type_multifeature_v1</code> table which labels cell types according to using soma, nucleus, dendrite, and spine features. \n",
    "\n",
    "Excitatory neurons are labeled by projection category (IT, ET, NP, CT, and SP for subplate). \n",
    "\n",
    "Inhibitory neurons follow labels based on targeting such as ITC (inhibitory targeting), STC (sparsely targeting), PTC (perisomatic targeting), and DTC (dendrite targeting), but might align more with molecular class than exact targeting for a given neuron, particularly among ITC/VIP cells.\n",
    "\n",
    "*Note:* Cells here without a label will remain black. These are either non-neuronal cells or potential neurons with large segmentation errors that did not pass quality check\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab28d10-9ec4-4f22-a5a5-6cb46cc833f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=150)\n",
    "ax.tick_params(labelsize=14)\n",
    "sns.scatterplot(\n",
    "    data=cell_df,  # this is the dataframe\n",
    "    x=\"volume\",\n",
    "    y=\"depth_um\",\n",
    "    size=1,\n",
    "    edgecolor=None,\n",
    "    alpha=0.005,\n",
    "    color=\"k\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=cell_df,\n",
    "    x=\"volume\",\n",
    "    y=\"depth_um\",\n",
    "    size=1,\n",
    "    edgecolor=None,\n",
    "    alpha=0.1,\n",
    "    color=\"k\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    hue=\"cell_type\",\n",
    ")\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel(r\"Volume ($\\mu m^3$)\", fontsize=16)\n",
    "ax.set_ylabel(r\"Depth ($\\mu m$)\", fontsize=16)\n",
    "ax.set_xlim(0, 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a125bc3-2eef-498e-8443-bc0320ccdfa8",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Sorting the synapse matrix with cell types\n",
    "    \n",
    "Let's combine the synaptic connecitivity with the cell type information. Below we provide logic for sorting a connectivity matrix using a list of labels.    \n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the proofread ids for those with a known cell type\n",
    "proof_root_ids = np.intersect1d(proof_root_ids, cell_df[\"pt_root_id\"].values)\n",
    "\n",
    "# Filter the cell type table for those with a proofread root id\n",
    "proof_cell_df = cell_df.set_index(\"pt_root_id\").loc[proof_root_ids]\n",
    "proof_cell_df = proof_cell_df.query(\"cell_type.notna()\")\n",
    "\n",
    "# NOTE: the adjacency matrix will be sorted according to this dataframe's index, so\n",
    "# we'll sort it by soma depth\n",
    "proof_cell_df = proof_cell_df.sort_values(\"pt_position_trform_y\")\n",
    "\n",
    "# Make adjacency, now including soma depth and cell type\n",
    "syn_mat = make_adjacency(syn_df, proof_cell_df, aggfunc=\"sum\")\n",
    "syn_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f52ecc",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "NOTE: there are slightly fewer cells in this adjacency matrix, because we are filtering for cells that have complete information in the cell table above.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97937880",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=200)\n",
    "sns.heatmap(\n",
    "    syn_mat,\n",
    "    cbar=True,\n",
    "    cmap=\"Greys\",\n",
    "    xticklabels=False,\n",
    "    yticklabels=False,\n",
    "    square=True,\n",
    "    vmax=3000,\n",
    "    ax=ax,\n",
    "    cbar_kws={\"label\": r\"Sum synapse size (voxels)\", \"shrink\": 0.5},\n",
    ")\n",
    "ax.spines[[\"left\", \"right\", \"top\", \"bottom\"]].set_visible(True)\n",
    "_ = ax.set(\n",
    "    xlabel=\"Postsynaptic cell (by depth)\",\n",
    "    ylabel=\"Presynaptic cell (by depth)\",\n",
    "    title=\"Adjacency matrix between proofread cells\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43db28-1b83-4e94-bb5c-0d097ede21d5",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 4:</b> There is a large amount of structure in the connectivity, just based on soma depth! However, some rows are very narrow in their connectivty while others are very wide.\n",
    "    \n",
    "<p><b>Discussion:</b> What are some explanations for why the connectivity plot has a strong diagonal component? In contrast, what does the wide connectivity in a row/column mean </p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a6c2f-8843-4747-9c9c-c42aab754957",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Add cell type logic to adjacency plot\n",
    "\n",
    "What about the effect of cell types on the connectivity matrix? We can add colors and subplots by cell type to make this matrix more tractable. We have packaged away the logic for this in `adjacencyplot` which can group and sort the adjacency matrix by metadata in the cell table.\n",
    "\n",
    "The logic here is similar to the plotting package `seaborn`, where different labels within the data can be leveraged to control different elements.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1492ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import adjacencyplot, cell_type_palette\n",
    "\n",
    "sns.set_context('paper', font_scale=1.0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), dpi=200)\n",
    "\n",
    "# render the adjacency plot\n",
    "adjacencyplot(\n",
    "    syn_mat,  # data values for the points\n",
    "    nodes=proof_cell_df,  # data to organize the x and y axis\n",
    "    groupby=[\"cell_type_coarse\", \"cell_type\"],  # categorical variables to organize by\n",
    "    sortby=\"pt_position_y\",  # sort within groups by variable\n",
    "    node_palette=cell_type_palette,\n",
    "    title=\"Proofread connectivity\",\n",
    "    edge_palette=\"Greys\",\n",
    "    hue_norm=(0, 2000),  # normalize the color scale for the edges\n",
    "    ax=ax,\n",
    "    label_fontsize=\"xx-small\",\n",
    "    title_fontsize=\"medium\",\n",
    "    arc_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490395d-3671-447b-93a0-d9cae2d4e540",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 5:</b> Now we have restructured the connectivity based on cell type. Find one of your example cells from earlier and identify it's row or column. Hint: query the <code>proof_cell_df</code> by your <code>root_id</code>\n",
    "\n",
    "<b>Discussion:</b> Describe the connectivity for your cell by who it targets and who it recieves inputs from.\n",
    "\n",
    "Then, for each row describe that cell type by it's major targets. Do you think there are more subgroups within the cell types?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94239cf-1dcd-4483-a943-bacc402826ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the cell type of your root_id:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f392473-c50e-4a22-913e-de71edc89edb",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Connection specificity onto compartment types\n",
    "Up until now we have considered all synapses between any two cells, but different synapses target different compartments on the post synaptic cell. \n",
    "\n",
    "![](../../figures/sss-diagram.png)\n",
    "\n",
    "For example, it is common understanding that:\n",
    "\n",
    "<ol>\n",
    "    <li> Synapses between excitatory->excitatory cells are onto spines</li>\n",
    "    <li> Synapses between inhibitory->excitatory cells are onto dendritic shaft</li>\n",
    "    <li> Synapses onto inhibitory cells are onto dendritic shaft</li>\n",
    "    <li> Basket cells target soma synapses </li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "Let's test this textbook understanding in the real data. \n",
    "\n",
    "<font size=4> For this you will need to load in data about the target compartment of the synapse, one of: spine, shaft, soma </font>\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea43ba-712a-4c51-8cf5-6c97ca712b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now load the table that includes the target structure and combine to your synapse matrix\n",
    "target_structure = pd.read_feather(\n",
    "    pjoin(data_dir, f\"syn_label_df_all_to_proofread_to_all_{mat_version}.feather\")\n",
    ")[\"tag\"]\n",
    "target_structure\n",
    "\n",
    "# Select the synapses between proofread cells\n",
    "proof_proof_syn_table = filter_synapse_table(\n",
    "    syn_df, pre_root_ids=proof_root_ids, post_root_ids=proof_root_ids\n",
    ").copy().set_index('id')\n",
    "\n",
    "# Combine the target information to the proofread synapses table\n",
    "proof_proof_syn_table[\"target_structure\"] = target_structure\n",
    "proof_proof_syn_table[\"target_structure\"] = proof_proof_syn_table[\n",
    "    \"target_structure\"\n",
    "].fillna(\"unknown\")\n",
    "\n",
    "print(proof_proof_syn_table[\"target_structure\"].value_counts())\n",
    "proof_proof_syn_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a3b51-2a69-4be5-84be-27a2326435ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot just synapses onto spine\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), dpi=200)\n",
    "\n",
    "category = 'spine' # This is synapses onto spines\n",
    "\n",
    "category_syns_df = proof_proof_syn_table.query(f\"target_structure == '{category}'\")\n",
    "category_syn_mat = make_adjacency(\n",
    "    category_syns_df, source_cell_index=proof_cell_df, aggfunc=\"sum\"\n",
    ")\n",
    "# render the adjacency plot\n",
    "adjacencyplot(\n",
    "    category_syn_mat,  # data values for the points\n",
    "    nodes=proof_cell_df,  # data to organize the x and y axis\n",
    "    groupby=[\"cell_type_coarse\", \"cell_type\"],  # categorical variables to organize by\n",
    "    sortby=\"pt_position_y\",  # sort within groups by variable\n",
    "    node_palette=cell_type_palette,\n",
    "    title=\"Proofread connectivity\",\n",
    "    edge_palette=\"Greys\",\n",
    "    hue_norm=(0, 2000),  # normalize the color scale for the edges\n",
    "    ax=ax,\n",
    "    label_fontsize=\"xx-small\",\n",
    "    title_fontsize=\"medium\",\n",
    "    arc_labels=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38d00e-695a-49cc-b5ce-9a9d865240d6",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 6:</b> Reproduce the plot above from 'spine' for 'shaft' and 'soma'\n",
    "\n",
    "<b>Discussion:</b> For each of the common cell-type connectivity assumptions above, which hold up in the data? \n",
    "\n",
    "Find one thing that does not match your expectation, and write it on the whiteboard.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981c3b1-5342-43ad-be46-d2755d3b749f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "## Bonus at the bottom of the workshop\n",
    "\n",
    "Treasure! For scrolling so far.\n",
    "\n",
    "If you are interested in exploring further, here is some code for computing the number and proportion of edges that go between cell types for each different target structure. This is useful for summarizing the observations above. Note that this is just chaining together some Pandas operations like groupby that we already saw.\n",
    "    \n",
    "</d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc484f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_proof_syn_table['pre_cell_type'] = proof_proof_syn_table['pre_pt_root_id'].map(\n",
    "    proof_cell_df[\"cell_type\"]\n",
    ")\n",
    "proof_proof_syn_table['post_cell_type'] = proof_proof_syn_table['post_pt_root_id'].map(\n",
    "    proof_cell_df[\"cell_type\"]\n",
    ")\n",
    "category_edge_info = (\n",
    "    proof_proof_syn_table.groupby([\"pre_cell_type\", \"post_cell_type\", \"target_structure\"])\n",
    "    .size()\n",
    "    .rename(\"edge_count\")\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    ")\n",
    "category_edge_info[\"edge_prop\"] = category_edge_info[\"edge_count\"] / (\n",
    "    category_edge_info.groupby([\"pre_cell_type\", \"post_cell_type\"])[\n",
    "        \"edge_count\"\n",
    "    ].transform(\"sum\")\n",
    ")\n",
    "category_edge_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
